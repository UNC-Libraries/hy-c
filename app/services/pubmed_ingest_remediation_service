class PubmedIngestRemediationService

  def self.find_and_resolve_duplicates!(since:, report_filepath:)
    duplicates = find_duplicate_dois(since: since, filepath: report_filepath)
    resolve_duplicates!(filepath: report_filepath) if duplicates.any?
  end

  def self.find_duplicate_dois(since:, filepath:)
    # Hash with default value as empty array
    duplicates = Hash.new { |h, k| h[k] = [] }
    # Limit search for article deposits from specified date onwards
    Article.where('deposited at >= ?', since).find_each(batch_size: 1000) do |work|
        Array(work.identifier).each do |id_val|
            # Only consider DOIs
            next unless id_val.start_with?('DOI: https://dx.doi.org/')
            doi = id_val.sub('DOI: https://dx.doi.org/', '')
            duplicates[doi] << work
        end
    end
    refined_duplicates = duplicates.select { |_doi, works| works.size > 1 }
    save_duplicate_report(refined_duplicates, filepath: filepath)
    #  returns { doi => [work1, work2, ...] }
    refined_duplicates
  end

  def self.resolve_duplicates!(filepath:)
    pairs = File.readlines(filepath).map { |line| JSON.parse(line.strip) }
    removed_count = 0
    pairs.each do |pair|
        doi = pair['doi']
        works = pair['work_ids'].map { |id| Article.find(id) }
        # Destroy the most recently deposited work, keep the earliest one
        work_to_keep = works.min_by { |w| w.deposited_at }
        works_to_remove = works - [work_to_keep]
        works_to_remove.each do |work|
            work.destroy
        end
        removed_count += works_to_remove.size
    end
    LogUtilsHelper.double_log("Resolved duplicates, removed #{removed_count} works", :info, tag: 'resolve_duplicates')
  end

  def self.save_duplicate_report(duplicates, filepath:)
    payload = duplicates.map { |doi, works| { doi: doi, work_ids: works.map(&:id) } }
    JsonFileUtilsHelper.write_json(payload, filepath)
    LogUtilsHelper.double_log("Saved duplicate report with #{payload.size} entries to #{filepath}", :info, tag: 'save_duplicate_report')
    rescue => e
        LogUtilsHelper.double_log("Failed to write duplicate report to #{filepath}: #{e.message}", :error, tag: 'save_duplicate_report')
    end
  end
end